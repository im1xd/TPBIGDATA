{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Create data.txt**"
      ],
      "metadata": {
        "id": "9fahKckTLu2I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhNymszSLm7_",
        "outputId": "c3d24417-0494-40ee-8d1d-270404d97471"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile data.txt\n",
        "spark makes big data easy\n",
        "big data needs spark power\n",
        "python is great for data processing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**dala mapper**"
      ],
      "metadata": {
        "id": "vwuy0r7AL2ny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mapper(line):\n",
        "    words = line.strip().split()\n",
        "    return [(word, 1) for word in words]\n",
        "# semple exemple\n",
        "print(mapper(\"big data needs spark power\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCKO1rKXL4T0",
        "outputId": "6dd5a7c2-2ef1-4600-ca34-6b0f5e50aaa3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('big', 1), ('data', 1), ('needs', 1), ('spark', 1), ('power', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**shuffle tajmi3**"
      ],
      "metadata": {
        "id": "egwbrDV7MBu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def shuffle(mapped_data):\n",
        "    grouped = defaultdict(list)\n",
        "    for key, value in mapped_data:\n",
        "        grouped[key].append(value)\n",
        "    return grouped\n"
      ],
      "metadata": {
        "id": "onX9ZvEcMEbZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**reducer (التجميع النهائي)**"
      ],
      "metadata": {
        "id": "0mil7rZ2MJuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reducer(grouped_data):\n",
        "    reduced = {}\n",
        "    for key, values in grouped_data.items():\n",
        "        reduced[key] = sum(values)\n",
        "    return reduced\n"
      ],
      "metadata": {
        "id": "xtOMitgCMKoz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5 mapreduce**"
      ],
      "metadata": {
        "id": "P331DWJbMP1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mapreduce(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    # Map\n",
        "    mapped = []\n",
        "    for line in lines:\n",
        "        mapped.extend(mapper(line))\n",
        "\n",
        "    print(\"Mapped Output (first 10):\", mapped[:10])\n",
        "\n",
        "    # Shuffle\n",
        "    grouped = shuffle(mapped)\n",
        "    print(\"\\nGrouped Data (sample):\", {k: grouped[k] for k in list(grouped)[:5]})\n",
        "\n",
        "    # Reduce\n",
        "    reduced = reducer(grouped)\n",
        "    return reduced\n",
        "\n",
        "results = mapreduce(\"data.txt\")\n",
        "print(\"\\nFinal Results:\")\n",
        "for word, count in sorted(results.items()):\n",
        "    print(f\"{word}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1Zrb2YbMSsS",
        "outputId": "ef5453f5-58bd-4129-e9f8-320154eed948"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapped Output (first 10): [('spark', 1), ('makes', 1), ('big', 1), ('data', 1), ('easy', 1), ('big', 1), ('data', 1), ('needs', 1), ('spark', 1), ('power', 1)]\n",
            "\n",
            "Grouped Data (sample): {'spark': [1, 1], 'makes': [1], 'big': [1, 1], 'data': [1, 1, 1], 'easy': [1]}\n",
            "\n",
            "Final Results:\n",
            "big: 2\n",
            "data: 3\n",
            "easy: 1\n",
            "for: 1\n",
            "great: 1\n",
            "is: 1\n",
            "makes: 1\n",
            "needs: 1\n",
            "power: 1\n",
            "processing: 1\n",
            "python: 1\n",
            "spark: 2\n"
          ]
        }
      ]
    }
  ]
}