# TP08 â€“ Simulating MapReduce Jobs on Google Colab

> Practical work for the **Big Data** course (Master 2 I2A, University of El Oued, 2025/2026).  
> Goal: understand the **map â†’ group/shuffle â†’ reduce** pattern by simulating MapReduce jobs in pure Python on Google Colab. :contentReference[oaicite:0]{index=0}  

---

## ðŸ“‚ Repository Contents

This repository contains three small MapReduce-style experiments, each implemented in Python / Google Colab:

- **Word Count** â€“ introductory example.
- **Sales per Region Analysis** â€“ applied example on CSV-like data.
- **Web Log Analysis** â€“ main exercise + bonus explorations. :contentReference[oaicite:1]{index=1}  

Suggested structure (adjust filenames if needed):

- `wordcount.ipynb` â€“ Word Count notebook  
- `sales_mapreduce.ipynb` â€“ Sales per Region notebook  
- `log_analysis_mapreduce.ipynb` â€“ Web Log Analysis notebook  

Data files (created inside the notebooks):

- `data.txt` â€“ input text for the Word Count example  
- `sales.txt` â€“ product sales dataset  
- `weblogs.txt` â€“ HTTP log dataset  

---

## ðŸ§  Concept: Map â†’ Group/Shuffle â†’ Reduce

All three examples follow the same pattern:

1. **Map**  
   - Read each line of the input file.  
   - Parse it and emit keyâ€“value pairs like `(key, value)`.

2. **Group / Shuffle**  
   - Group all values sharing the same key (conceptually like the shuffle phase in Hadoop).

3. **Reduce**  
   - Aggregate the grouped values (e.g. `sum`, `count`) to compute the final result.

This simulates how distributed frameworks like **Hadoop MapReduce** or **Spark** process large datasets, but here everything runs locally in Python on a single machine / Colab runtime. :contentReference[oaicite:2]{index=2}  

---

## ðŸ“˜ Example
Create a virtual environment and install Jupyter if needed.

Launch Jupyter:

jupyter notebook


Open the notebooks and run them cell by cell.
